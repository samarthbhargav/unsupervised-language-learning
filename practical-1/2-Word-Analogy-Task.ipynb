{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "%matplotlib inline\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_analogy_data(path):\n",
    "    with open(path) as reader:\n",
    "        analogy_data = []\n",
    "        task_labels = []\n",
    "        for line in reader:\n",
    "            if line.startswith(\":\"):\n",
    "                task = line.strip().strip(\":\").strip()\n",
    "                continue\n",
    "            # convert to lower-case \n",
    "            analogy_data.append(line.strip().lower().split())\n",
    "            task_labels.append(task)\n",
    "    return analogy_data, task_labels\n",
    "analogy_data, task_labels = read_analogy_data(\"./data/questions-words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['athens', 'greece', 'baghdad', 'iraq'],\n",
       "  ['athens', 'greece', 'bangkok', 'thailand'],\n",
       "  ['athens', 'greece', 'beijing', 'china'],\n",
       "  ['athens', 'greece', 'berlin', 'germany'],\n",
       "  ['athens', 'greece', 'bern', 'switzerland'],\n",
       "  ['athens', 'greece', 'cairo', 'egypt'],\n",
       "  ['athens', 'greece', 'canberra', 'australia'],\n",
       "  ['athens', 'greece', 'hanoi', 'vietnam'],\n",
       "  ['athens', 'greece', 'havana', 'cuba'],\n",
       "  ['athens', 'greece', 'helsinki', 'finland']],\n",
       " ['capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of sub-categories\n",
    "analogy_data[:10], task_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'capital-common-countries': 506,\n",
       "         'capital-world': 4524,\n",
       "         'city-in-state': 2467,\n",
       "         'currency': 866,\n",
       "         'family': 506,\n",
       "         'gram1-adjective-to-adverb': 992,\n",
       "         'gram2-opposite': 812,\n",
       "         'gram3-comparative': 1332,\n",
       "         'gram4-superlative': 1122,\n",
       "         'gram5-present-participle': 1056,\n",
       "         'gram6-nationality-adjective': 1599,\n",
       "         'gram7-past-tense': 1560,\n",
       "         'gram8-plural': 1332,\n",
       "         'gram9-plural-verbs': 870})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(task_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow2_sim = load_model(\"bow2.words\")\n",
    "bow5_sim = load_model(\"bow5.words\")\n",
    "deps_sim = load_model(\"deps.words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.5\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def reciprocal_rank(correct_value, results):\n",
    "    try:\n",
    "        position = results.index(correct_value)\n",
    "        return 1 / (position + 1)\n",
    "    except:\n",
    "        return 0 \n",
    "\n",
    "# tests\n",
    "print(reciprocal_rank(\"cats\", [\"catten\", \"cati\", \"cats\"]))\n",
    "print(reciprocal_rank(\"tori\", [\"catten\", \"tori\", \"cats\"]))\n",
    "print(reciprocal_rank(\"virus\", [\"virus\", \"cati\", \"cats\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wv(model, a, a_star, b):\n",
    "    if a not in model.word_index or a_star not in model.word_index or b not in model.word_index:\n",
    "        return None\n",
    "    a, a_star, b = model[a], model[a_star], model[b]\n",
    "    v = a_star - a\n",
    "    b_star = b + v\n",
    "    return b_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_csim(matrix, vector):\n",
    "    \"\"\"\n",
    "    Compute the cosine distances between each row of matrix and vector.\n",
    "    \"\"\"\n",
    "    v = vector.reshape(1, -1)\n",
    "    return 1 - scipy.spatial.distance.cdist(matrix, v, 'cosine').reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data):\n",
    "    start_time = time.time()\n",
    "    overall_correct = []\n",
    "    overall_rr = []\n",
    "    task_correct = defaultdict(list)\n",
    "    task_rr = defaultdict(list)\n",
    "    skipped = 0\n",
    "    rev_index = dict([(v,k) for k, v in model.word_index.items()])\n",
    "    embeddings = np.array(model.embeddings)\n",
    "    for index, (tlab, (a, a_star, b, b_star_actual)) in enumerate(zip(task_labels, data)):\n",
    "        if b_star_actual not in model.word_index:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        b_star = compute_wv(model, a, a_star, b)\n",
    "\n",
    "        if b_star is None:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        results_score = cos_csim(embeddings, b_star)\n",
    "        results = [(rev_index[idx], result) for idx, result in enumerate(results_score)]\n",
    "        results.sort(key=lambda _ : -_[1])\n",
    "        # exclude these\n",
    "        results = [r[0] for r in results if r[0] not in {a, a_star, b}]\n",
    "        if results[0] == b_star_actual:\n",
    "            overall_correct.append(1)\n",
    "            task_correct[tlab].append(1)\n",
    "        else:\n",
    "            overall_correct.append(0)\n",
    "            task_correct[tlab].append(0)\n",
    "        \n",
    "        overall_rr.append(reciprocal_rank(b_star_actual, results))\n",
    "        task_rr[tlab].append(reciprocal_rank(b_star_actual, results))\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            print(\"{}: {} minutes\".format(index, (time.time() - start_time)/60))\n",
    "    \n",
    "    accuracy = sum(overall_correct) / len(overall_correct)\n",
    "    print(\"Accuracy: {}, MRR: {}\".format(accuracy, np.mean(overall_rr)))\n",
    "    \n",
    "    \n",
    "    for task_label in np.unique(task_labels):\n",
    "        accuracy = sum(task_correct[task_label]) / len(task_correct[task_label])\n",
    "        print(\"Task: {}:: Accuracy: {}, MRR: {}\".format(task_label, accuracy, np.mean(task_rr[task_label])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output is saved in the last cell (executed on different laptops)\n",
    "evaluate_model(deps_sim, analogy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output is saved in the last cell (executed on different laptops)\n",
    "evaluate_model(bow5_sim, analogy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.02026971975962321 minutes\n",
      "100: 1.092841883500417 minutes\n",
      "200: 2.168443016211192 minutes\n",
      "300: 3.2496140877405804 minutes\n",
      "400: 4.3660209973653155 minutes\n",
      "500: 5.441014126936595 minutes\n",
      "600: 6.513348948955536 minutes\n",
      "700: 7.589607067902883 minutes\n",
      "800: 8.66030620733897 minutes\n",
      "900: 9.731489197413127 minutes\n",
      "1000: 10.802808781464895 minutes\n",
      "1100: 11.875128746032715 minutes\n",
      "1200: 12.951686759789785 minutes\n",
      "1300: 14.02580695549647 minutes\n",
      "1400: 15.104666503270467 minutes\n",
      "1500: 16.176827359199525 minutes\n",
      "1600: 17.251885414123535 minutes\n",
      "1700: 18.32343314488729 minutes\n",
      "1800: 19.398509856065115 minutes\n",
      "1900: 20.47016796271006 minutes\n",
      "2000: 21.540792949994405 minutes\n",
      "2100: 22.615817642211915 minutes\n",
      "2200: 23.68942538102468 minutes\n",
      "2300: 24.76369526386261 minutes\n",
      "2400: 25.836255248387655 minutes\n",
      "2500: 26.90896447499593 minutes\n",
      "2600: 27.98992429971695 minutes\n",
      "2700: 29.071549129486083 minutes\n",
      "2800: 30.145808299382526 minutes\n",
      "2900: 31.22102496623993 minutes\n",
      "3000: 32.2964684844017 minutes\n",
      "3100: 33.37023443778356 minutes\n",
      "3200: 34.45564135313034 minutes\n",
      "3300: 35.52732603549957 minutes\n",
      "3400: 36.59824920097987 minutes\n",
      "3500: 57.79535215298335 minutes\n",
      "3600: 58.87696475187938 minutes\n",
      "3700: 59.97688893477122 minutes\n",
      "3800: 61.07562000354131 minutes\n",
      "3900: 62.14968534310659 minutes\n",
      "4000: 63.226322229703264 minutes\n",
      "4100: 64.2971629579862 minutes\n",
      "4200: 65.3672050356865 minutes\n",
      "4300: 66.43700902859369 minutes\n",
      "4400: 67.5081149260203 minutes\n",
      "4500: 68.57975004116695 minutes\n",
      "4600: 69.64923006693522 minutes\n",
      "4700: 70.71996182203293 minutes\n",
      "4800: 71.79157513777415 minutes\n",
      "4900: 72.86192350387573 minutes\n",
      "5000: 73.94242796500524 minutes\n",
      "5100: 74.9396698474884 minutes\n",
      "5200: 75.85291252930959 minutes\n",
      "5300: 76.78462419112523 minutes\n",
      "5400: 77.71444772084554 minutes\n",
      "5600: 79.05556709766388 minutes\n",
      "5700: 79.70230636994044 minutes\n",
      "5900: 81.29486514727274 minutes\n",
      "6000: 82.36878933111826 minutes\n",
      "6100: 83.44363456964493 minutes\n",
      "6200: 84.51796153783798 minutes\n",
      "6300: 85.58939592838287 minutes\n",
      "6400: 86.29316116571427 minutes\n",
      "6500: 86.95680105288824 minutes\n",
      "6600: 87.61966246763865 minutes\n",
      "6700: 88.28333450555802 minutes\n",
      "6800: 88.94367216825485 minutes\n",
      "6900: 89.60248736540477 minutes\n",
      "7000: 90.26173174381256 minutes\n",
      "7100: 90.92116292715073 minutes\n",
      "7200: 91.58182035287221 minutes\n",
      "7300: 92.24094515244165 minutes\n",
      "7400: 92.90062575737635 minutes\n",
      "7500: 93.56120291550954 minutes\n",
      "7600: 94.22167142232259 minutes\n",
      "7700: 94.88097811937332 minutes\n",
      "7800: 95.54038455088933 minutes\n",
      "7900: 96.20011361837388 minutes\n",
      "8000: 96.86005212863286 minutes\n",
      "8100: 97.5204143722852 minutes\n",
      "8200: 98.18002010981242 minutes\n",
      "8300: 98.8398655851682 minutes\n",
      "8400: 99.49869372049967 minutes\n",
      "8500: 100.15935905774434 minutes\n",
      "8600: 100.8182870944341 minutes\n",
      "8700: 101.47619659503302 minutes\n",
      "8800: 102.1349554737409 minutes\n",
      "8900: 102.79446879227956 minutes\n",
      "9000: 103.45553698937098 minutes\n",
      "9100: 104.11714913050334 minutes\n",
      "9200: 104.7790548245112 minutes\n",
      "9300: 105.44091705481212 minutes\n",
      "9400: 106.10230784018835 minutes\n",
      "9500: 106.76361702283224 minutes\n",
      "9600: 107.42748152017593 minutes\n",
      "9700: 108.08919655481974 minutes\n",
      "9800: 108.75275292396546 minutes\n",
      "9900: 109.4151005268097 minutes\n",
      "10000: 110.07623182137807 minutes\n",
      "10100: 110.73648783365886 minutes\n",
      "10200: 111.39842348893484 minutes\n",
      "10300: 112.0612779021263 minutes\n",
      "10400: 112.72488978306453 minutes\n",
      "10500: 113.38649655977885 minutes\n",
      "10600: 114.0482146024704 minutes\n",
      "10700: 114.71043042739232 minutes\n",
      "10800: 115.37205456892649 minutes\n",
      "10900: 116.0330801486969 minutes\n",
      "11000: 116.69468144973119 minutes\n",
      "11100: 117.35745825370152 minutes\n",
      "11200: 118.01950203577677 minutes\n",
      "11300: 118.70499863624573 minutes\n",
      "11400: 119.38205495278041 minutes\n",
      "11500: 120.04739524523417 minutes\n",
      "11600: 120.71517699956894 minutes\n",
      "11700: 121.42591859499613 minutes\n",
      "11800: 122.11144683361053 minutes\n",
      "11900: 122.77585923274358 minutes\n",
      "12000: 123.45922794342042 minutes\n",
      "12100: 124.11722805897395 minutes\n",
      "12200: 124.79900388320287 minutes\n",
      "12300: 125.46645861466726 minutes\n",
      "12400: 126.11023211479187 minutes\n",
      "12500: 126.75278752247492 minutes\n",
      "12600: 127.39477389653524 minutes\n",
      "12700: 128.03779936234156 minutes\n",
      "12900: 129.31948672533036 minutes\n",
      "13000: 129.75626727342606 minutes\n",
      "13100: 130.40045763254165 minutes\n",
      "13200: 131.05920468171436 minutes\n",
      "13300: 131.722254995505 minutes\n",
      "13400: 132.3904758175214 minutes\n",
      "13500: 133.05834304889044 minutes\n",
      "13600: 133.72642693519592 minutes\n",
      "13700: 134.39498212734858 minutes\n",
      "13800: 135.06255569855372 minutes\n",
      "13900: 135.72704002857208 minutes\n",
      "14000: 136.3919115583102 minutes\n",
      "14100: 137.05722221533458 minutes\n",
      "14200: 137.7210999528567 minutes\n",
      "14300: 138.38278274933498 minutes\n",
      "14400: 139.04480131864548 minutes\n",
      "14500: 139.70663384199142 minutes\n",
      "14600: 140.36928177277247 minutes\n",
      "14700: 141.03170119524003 minutes\n",
      "14800: 141.69500919977824 minutes\n",
      "14900: 142.35728681484858 minutes\n",
      "15000: 143.02046893040338 minutes\n",
      "15100: 143.68322301705678 minutes\n",
      "15200: 144.3440476377805 minutes\n",
      "15300: 145.00475845734277 minutes\n",
      "15400: 145.6640903353691 minutes\n",
      "15500: 146.33446340958278 minutes\n",
      "15600: 146.9956152876218 minutes\n",
      "15700: 147.65529681841534 minutes\n",
      "15800: 148.3147686243057 minutes\n",
      "15900: 148.9763475616773 minutes\n",
      "16000: 149.6375674009323 minutes\n",
      "16100: 150.3061529358228 minutes\n",
      "16200: 150.99141180117925 minutes\n",
      "16300: 151.66034754514695 minutes\n",
      "16400: 152.32459497054418 minutes\n",
      "16500: 152.98824023405712 minutes\n",
      "16600: 153.65045841534933 minutes\n",
      "16700: 154.31275096734365 minutes\n",
      "16800: 154.97497431437174 minutes\n",
      "16900: 155.6352348089218 minutes\n",
      "17000: 156.29660784403484 minutes\n",
      "17100: 156.95813060601552 minutes\n",
      "17200: 157.62016785144806 minutes\n",
      "17300: 158.28209082285562 minutes\n",
      "17400: 158.94449969530106 minutes\n",
      "17500: 159.60968055725098 minutes\n",
      "17600: 160.2718698978424 minutes\n",
      "17700: 160.943002084891 minutes\n",
      "17800: 161.60553786357244 minutes\n",
      "17900: 162.27010345856348 minutes\n",
      "18000: 162.9340054869652 minutes\n",
      "18100: 163.59697266022366 minutes\n",
      "18200: 164.25999751488368 minutes\n",
      "18300: 164.92272050778072 minutes\n",
      "18400: 165.58401574691138 minutes\n",
      "18500: 166.2480438431104 minutes\n",
      "18600: 166.91950068473815 minutes\n",
      "18700: 167.59006991783778 minutes\n",
      "18800: 168.25934743881226 minutes\n",
      "18900: 168.9287644902865 minutes\n",
      "19000: 169.59001345237095 minutes\n",
      "19100: 170.25126917362212 minutes\n",
      "19200: 170.91525849103928 minutes\n",
      "19300: 203.46231131156284 minutes\n",
      "19400: 204.5601312438647 minutes\n",
      "19500: 205.63994869788488 minutes\n",
      "Accuracy: 0.5928964586146017, MRR: 0.6738476055502349\n",
      "Task: capital-common-countries:: Accuracy: 0.8359683794466403, MRR: 0.8817258077741364\n",
      "Task: capital-world:: Accuracy: 0.6301945181255526, MRR: 0.7194812770755393\n",
      "Task: city-in-state:: Accuracy: 0.3923794081880827, MRR: 0.4976112176150989\n",
      "Task: currency:: Accuracy: 0.1130030959752322, MRR: 0.14801165297319077\n",
      "Task: family:: Accuracy: 0.7944664031620553, MRR: 0.8538134449938941\n",
      "Task: gram1-adjective-to-adverb:: Accuracy: 0.1592741935483871, MRR: 0.2357158319077029\n",
      "Task: gram2-opposite:: Accuracy: 0.35591133004926107, MRR: 0.42342064938705753\n",
      "Task: gram3-comparative:: Accuracy: 0.8956456456456456, MRR: 0.9388533621508531\n",
      "Task: gram4-superlative:: Accuracy: 0.6306818181818182, MRR: 0.7300379939681495\n",
      "Task: gram5-present-participle:: Accuracy: 0.6268939393939394, MRR: 0.7470184960322382\n",
      "Task: gram6-nationality-adjective:: Accuracy: 0.7417135709818636, MRR: 0.8073374035779143\n",
      "Task: gram7-past-tense:: Accuracy: 0.5570512820512821, MRR: 0.6625581806410229\n",
      "Task: gram8-plural:: Accuracy: 0.7327327327327328, MRR: 0.7926475754522675\n",
      "Task: gram9-plural-verbs:: Accuracy: 0.8068965517241379, MRR: 0.8647319328912093\n"
     ]
    }
   ],
   "source": [
    "# The output is saved in the last cell (executed on different laptops)\n",
    "evaluate_model(bow2_sim, analogy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of the analogy task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-7btt\" rowspan=\"2\">Task</th>\n",
    "    <th class=\"tg-7btt\" colspan=\"2\">BOW2</th>\n",
    "    <th class=\"tg-7btt\" colspan=\"2\">BOW5</th>\n",
    "    <th class=\"tg-amwm\" colspan=\"2\">DEPS</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-7btt\">Accuracy</td>\n",
    "    <td class=\"tg-7btt\">MRR</td>\n",
    "    <td class=\"tg-7btt\">Accuracy</td>\n",
    "    <td class=\"tg-7btt\">MRR</td>\n",
    "    <td class=\"tg-amwm\">Accuracy</td>\n",
    "    <td class=\"tg-amwm\">MRR</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">capital-common-countries</td>\n",
    "    <td class=\"tg-c3ow\">0.8359</td>\n",
    "    <td class=\"tg-c3ow\">0.8817</td>\n",
    "    <td class=\"tg-7btt\">0.9407</td>\n",
    "    <td class=\"tg-7btt\">0.9639</td>\n",
    "    <td class=\"tg-baqh\">0.3517</td>\n",
    "    <td class=\"tg-baqh\">0.4938</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">capital-world</td>\n",
    "    <td class=\"tg-c3ow\">0.63019</td>\n",
    "    <td class=\"tg-c3ow\">0.7194</td>\n",
    "    <td class=\"tg-7btt\">0.7029</td>\n",
    "    <td class=\"tg-7btt\">0.7988</td>\n",
    "    <td class=\"tg-baqh\">0.1120</td>\n",
    "    <td class=\"tg-baqh\">0.2034</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">city-in-state</td>\n",
    "    <td class=\"tg-c3ow\">0.39237</td>\n",
    "    <td class=\"tg-c3ow\">0.4976</td>\n",
    "    <td class=\"tg-7btt\">0.5127</td>\n",
    "    <td class=\"tg-7btt\">0.6213</td>\n",
    "    <td class=\"tg-baqh\">0.1228</td>\n",
    "    <td class=\"tg-baqh\">0.2208</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">currency</td>\n",
    "    <td class=\"tg-c3ow\">0.1130</td>\n",
    "    <td class=\"tg-c3ow\">0.1480</td>\n",
    "    <td class=\"tg-7btt\">0.1222</td>\n",
    "    <td class=\"tg-7btt\">0.1686</td>\n",
    "    <td class=\"tg-baqh\">0.0637</td>\n",
    "    <td class=\"tg-baqh\">0.0958</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">family</td>\n",
    "    <td class=\"tg-c3ow\">0.7944</td>\n",
    "    <td class=\"tg-c3ow\">0.8538</td>\n",
    "    <td class=\"tg-7btt\">0.8181</td>\n",
    "    <td class=\"tg-7btt\">0.8698</td>\n",
    "    <td class=\"tg-baqh\">0.8162</td>\n",
    "    <td class=\"tg-baqh\">0.8541</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">gram1-adjective-to-adverb</td>\n",
    "    <td class=\"tg-c3ow\">0.1592</td>\n",
    "    <td class=\"tg-c3ow\">0.2357</td>\n",
    "    <td class=\"tg-7btt\">0.1693</td>\n",
    "    <td class=\"tg-7btt\">0.2721</td>\n",
    "    <td class=\"tg-baqh\">0.0342</td>\n",
    "    <td class=\"tg-baqh\">0.0670</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">gram2-opposite</td>\n",
    "    <td class=\"tg-c3ow\">0.3559</td>\n",
    "    <td class=\"tg-c3ow\">0.4234</td>\n",
    "    <td class=\"tg-c3ow\">0.3633</td>\n",
    "    <td class=\"tg-c3ow\">0.4321</td>\n",
    "    <td class=\"tg-amwm\">0.4002</td>\n",
    "    <td class=\"tg-amwm\">0.4763</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">gram3-comparative</td>\n",
    "    <td class=\"tg-amwm\">0.8956</td>\n",
    "    <td class=\"tg-amwm\">0.9388</td>\n",
    "    <td class=\"tg-baqh\">0.8303</td>\n",
    "    <td class=\"tg-baqh\">0.8916</td>\n",
    "    <td class=\"tg-baqh\">0.8010</td>\n",
    "    <td class=\"tg-baqh\">0.8534</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">gram4-superlative</td>\n",
    "    <td class=\"tg-amwm\">0.6306</td>\n",
    "    <td class=\"tg-amwm\">0.7300</td>\n",
    "    <td class=\"tg-baqh\">0.5710</td>\n",
    "    <td class=\"tg-baqh\">0.6987</td>\n",
    "    <td class=\"tg-baqh\">0.5606</td>\n",
    "    <td class=\"tg-baqh\">0.6372</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">gram5-present-participle</td>\n",
    "    <td class=\"tg-baqh\">0.6268</td>\n",
    "    <td class=\"tg-baqh\">0.7470</td>\n",
    "    <td class=\"tg-amwm\">0.6704</td>\n",
    "    <td class=\"tg-amwm\">0.7818</td>\n",
    "    <td class=\"tg-baqh\">0.6467</td>\n",
    "    <td class=\"tg-baqh\">0.7402</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">gram6-nationality-adjective</td>\n",
    "    <td class=\"tg-baqh\">0.7417</td>\n",
    "    <td class=\"tg-baqh\">0.8073</td>\n",
    "    <td class=\"tg-amwm\">0.8236</td>\n",
    "    <td class=\"tg-amwm\">0.8648</td>\n",
    "    <td class=\"tg-baqh\">0.1213</td>\n",
    "    <td class=\"tg-baqh\">0.2198</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">gram7-past-tense</td>\n",
    "    <td class=\"tg-baqh\">0.5570</td>\n",
    "    <td class=\"tg-amwm\">0.6625</td>\n",
    "    <td class=\"tg-baqh\">0.5467</td>\n",
    "    <td class=\"tg-baqh\">0.6661</td>\n",
    "    <td class=\"tg-baqh\">0.6589</td>\n",
    "    <td class=\"tg-amwm\">0.7319</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">gram8-plural</td>\n",
    "    <td class=\"tg-amwm\">0.7327</td>\n",
    "    <td class=\"tg-amwm\">0.7926</td>\n",
    "    <td class=\"tg-baqh\">0.6681</td>\n",
    "    <td class=\"tg-baqh\">0.7522</td>\n",
    "    <td class=\"tg-baqh\">0.6756</td>\n",
    "    <td class=\"tg-baqh\">0.7478</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">gram9-plural-verbs</td>\n",
    "    <td class=\"tg-baqh\">0.8068</td>\n",
    "    <td class=\"tg-baqh\">0.8647</td>\n",
    "    <td class=\"tg-baqh\">0.7356</td>\n",
    "    <td class=\"tg-baqh\">0.8217</td>\n",
    "    <td class=\"tg-amwm\">0.9091</td>\n",
    "    <td class=\"tg-amwm\">0.9447</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">Overall</td>\n",
    "    <td class=\"tg-baqh\">0.5928</td>\n",
    "    <td class=\"tg-baqh\">0.6738</td>\n",
    "    <td class=\"tg-baqh\">0.6228</td>\n",
    "    <td class=\"tg-amwm\">0.7111</td>\n",
    "    <td class=\"tg-baqh\">0.3671</td>\n",
    "    <td class=\"tg-baqh\">0.4457</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of Quantitative Results\n",
    "\n",
    "In this section we'll analyze the results obtained in the previous section. We make the following observations:\n",
    "\n",
    "- The best performing model is the BOW5 model, and the worst performing model overall is the DEPS model.\n",
    "- The BOW5 models is best in 8/14 tasks, and the DEPS and BOW2 model performs the best in 3/14 tasks each. \n",
    "- All models perform very badly on the 'gram1-adjective-to-adverb' and 'currency' sub-tasks, suggesting that these models do not capture the requisite information necessary to succeed in these tasks. We hypothesize that the models perform badly on the 'currency' task because of data sparsity problems (we explore this more in the qualitative results section). The DEPS models performs especially bad in this task, suggesting that Dependency based embeddings aren't suited for this type of question\n",
    "- We also note that the BOW5 and BOW2 achieve comparable performance on most of the tasks. \n",
    "- The largest gaps in performance between the BOW and DEPS models is in the 'gram6-nationality-adjective' task (we explore why in the next section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis\n",
    "\n",
    "In this section, we'll perform qualitative analysis to support some of the conclusions made in the previous sections. We'll start with sampling 5 questions randomly from the analogy data and then executing the 3 models to compare their outputs. The analysis follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"BOW2\", bow2_sim),\n",
    "    (\"BOW5\", bow5_sim),\n",
    "    (\"DEPS\", deps_sim)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: capital-common-countries\n",
      "\tmadrid:spain::islamabad:pakistan\n",
      "\t\tBOW2:: Top 5 results: ['pakistan', 'afghanistan', 'srilanka', 'arabia', 'tajikistan']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['pakistan', 'sindh', 'karachi', 'gilgit-baltistan', 'peshawar']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['bhutan', 'turkmenistan', 'arabia', 'tajikistan', 'fennoscandia']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.02702702702702703\n",
      "\n",
      "\n",
      "\n",
      "\tbangkok:thailand::oslo:norway\n",
      "\t\tBOW2:: Top 5 results: ['norway', 'finland', 'sweden', 'trondheim', 'iceland']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['norway', 'sweden', 'stavanger', 'trondheim', 'denmark']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['slovenia', 'finland', 'denmark', 'sweden', 'slovakia']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.1111111111111111\n",
      "\n",
      "\n",
      "\n",
      "\tathens:greece::london:england\n",
      "\t\tBOW2:: Top 5 results: ['scandinavia', 'britain', 'germany', 'belgium', 'italy']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.07692307692307693\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['england', 'stepney', 'lewisham', 'islington', 'ealing']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['italy', 'germany', 'britain', 'belgium', 'australasia']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.16666666666666666\n",
      "\n",
      "\n",
      "\n",
      "\tottawa:canada::athens:greece\n",
      "\t\tBOW2:: Top 5 results: ['greece', 'cyprus', 'macedonia', 'crete', 'boeotia']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['greece', 'crete', 'thessaloniki', 'cyprus', 'italy']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['greece', 'sweden', 'finland', 'iceland', 'norway']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tcairo:egypt::moscow:russia\n",
      "\t\tBOW2:: Top 5 results: ['russia', 'yaroslavl', 'novgorod', 'kazakhstan', 'belarus']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['russia', 'ukraine', 'ussr', 'kazakhstan', 'kiev']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['russia', 'armenia', 'syria', 'hungary', 'romania']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: capital-world\n",
      "\tbratislava:slovakia::dushanbe:tajikistan\n",
      "\t\tBOW2:: Top 5 results: ['tajikistan', 'uzbekistan', 'kyrgyzstan', 'kazakhstan', 'turkmenistan']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['uzbekistan', 'kyrgyzstan', 'tajikistan', 'kazakhstan', 'turkmenistan']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.3333333333333333\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['turkmenistan', 'mauritania', 'tajikistan', 'belorussia', 'congo-brazzaville']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.3333333333333333\n",
      "\n",
      "\n",
      "\n",
      "\tantananarivo:madagascar::banjul:gambia\n",
      "\t\tBOW2:: Top 5 results: ['mauritius', 'seychelles', 'gambia', 'namibia', 'tanzania']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.3333333333333333\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['seychelles', 'gambia', 'mozambique', 'guinea-bissau', 'gabon']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['réunion', 'gabon', 'aldabra', 'vanuatu', 'guadeloupe']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.002967359050445104\n",
      "\n",
      "\n",
      "\n",
      "\tlilongwe:malawi::riga:latvia\n",
      "\t\tBOW2:: Top 5 results: ['latvia', 'lithuania', 'finland', 'ukraine', 'vilnius']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['latvia', 'finland', 'belarus', 'lithuania', 'ukraine']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['namibia', 'tanzania', 'zambia', 'lesotho', 'swaziland']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.03571428571428571\n",
      "\n",
      "\n",
      "\n",
      "\tkathmandu:nepal::minsk:belarus\n",
      "\t\tBOW2:: Top 5 results: ['belarus', 'ukraine', 'belorussia', 'vitebsk', 'mogilev']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['belarus', 'ukraine', 'kazakhstan', 'latvia', 'gomel']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['vojvodina', 'kazakhstan', 'bosnia-herzegovina', 'belarus', 'uzbekistan']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.25\n",
      "\n",
      "\n",
      "\n",
      "\thelsinki:finland::oslo:norway\n",
      "\t\tBOW2:: Top 5 results: ['norway', 'sweden', 'denmark', 'iceland', 'rogaland']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['norway', 'sweden', 'denmark', 'iceland', 'trondheim']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['sweden', 'norway', 'iceland', 'serbia', 'latvia']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: city-in-state\n",
      "\tdenver:colorado::portland:oregon\n",
      "\t\tBOW2:: Top 5 results: ['oregon', 'maine', 'vermont', 'arizona', 'corvallis']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['oregon', 'maine', 'idaho', 'corvallis', 'vermont']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['wisconsin', 'vermont', 'utah', 'oregon', 'arizona']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.25\n",
      "\n",
      "\n",
      "\n",
      "\tphiladelphia:pennsylvania::arlington:texas\n",
      "\t\tBOW2:: Top 5 results: ['loudoun', 'rockbridge', 'kentucky', 'vermont', 'conecuh']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.00012634238787113077\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['fauquier', 'loudoun', 'rockbridge', 'maryland', 'goochland']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.0011876484560570072\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['illinois', 'vermont', 'maryland', 'kentucky', 'missouri']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.02702702702702703\n",
      "\n",
      "\n",
      "\n",
      "\tarlington:texas::orlando:florida\n",
      "\t\tBOW2:: Top 5 results: ['florida', 'tulsa', 'tampa', 'alabama', 'tallahassee']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['florida', 'tampa', 'miami', 'gainesville', 'jacksonville']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['florida', 'tx', 'oklahoma', 'arizona', 'nev']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tcleveland:ohio::arlington:texas\n",
      "\t\tBOW2:: Top 5 results: ['kentucky', 'goochland', 'connecticut', 'rockbridge', 'fauquier']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.001095290251916758\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['virginia', 'fauquier', 'kentucky', 'centreville', 'blacksburg']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.0024096385542168677\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['missouri', 'illinois', 'pennsylvania', 'kentucky', 'vermont']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.019230769230769232\n",
      "\n",
      "\n",
      "\n",
      "\tmiami:florida::chandler:arizona\n",
      "\t\tBOW2:: Top 5 results: ['barbour', 'birdwell', 'pingree', 'bidwell', 'mcintire']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.0004424778761061947\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['payne', 'briggs', 'fletcher', 'miller', 'baxter']\n",
      "\t\tBOW5:: Reciprocal Rank: 9.378223764419019e-05\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['kearns', 'dyer', 'keough', 'stackhouse', 'raynor']\n",
      "\t\tDEPS:: Reciprocal Rank: 5.603496581867085e-05\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: currency\n",
      "\tpoland:zloty::india:rupee\n",
      "\n",
      "\n",
      "\tarmenia:dram::argentina:peso\n",
      "\t\tBOW2:: Top 5 results: ['sram', 'eprom', 'dimm', 'eeprom', 'sdram']\n",
      "\t\tBOW2:: Reciprocal Rank: 3.9916972696790676e-05\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['sram', 'ssds', 'dimm', 'on-chip', 'random-access']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.00022789425706472196\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['sram', 'ddr2', 'sdram', 'eeprom', 'dimm']\n",
      "\t\tDEPS:: Reciprocal Rank: 3.0839449824215136e-05\n",
      "\n",
      "\n",
      "\n",
      "\talgeria:dinar::thailand:baht\n",
      "\t\tBOW2:: Top 5 results: ['dirham', 'forint', 'ringgit', 'renminbi', 'baht']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.2\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['ringgit', 'renminbi', 'rupiah', 'phra', 'banknote']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.09090909090909091\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['dirham', 'rupee', 'forint', 'ringgit', 'shekel']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.012987012987012988\n",
      "\n",
      "\n",
      "\n",
      "\tthailand:baht::bulgaria:lev\n",
      "\t\tBOW2:: Top 5 results: ['rubles', 'litas', 'dkk', 'reichsmark', 'guilders']\n",
      "\t\tBOW2:: Reciprocal Rank: 3.508771929824561e-05\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['rubles', 'roubles', 'florins', 'euros', 'drachmas']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.0009950248756218905\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['reichsmark', 'roubles', 'guilders', 'dkk', 'pesetas']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.818777054308683e-05\n",
      "\n",
      "\n",
      "\n",
      "\tdenmark:krone::argentina:peso\n",
      "\t\tBOW2:: Top 5 results: ['peseta', 'rial', 'escudo', 'lire', 'candela']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.16666666666666666\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['peso', 'cndor', 'pataca', 'pesos', 'oriente']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['peso', 'rupiah', 'rial', 'peseta', 'lira']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: family\n",
      "\tnephew:niece::husband:wife\n",
      "\t\tBOW2:: Top 5 results: ['mother-in-law', 'fianc', 'fiance', 'boyfriend', 'ex-husband']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.0625\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['mother-in-law', 'fianc', 'stepmother', 'sister-in-law', 'aunt']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.034482758620689655\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['fiance', 'fiancé', 'mother-in-law', 'boyfriend', 'fiancee']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.08333333333333333\n",
      "\n",
      "\n",
      "\n",
      "\tbrothers:sisters::prince:princess\n",
      "\t\tBOW2:: Top 5 results: ['princess', 'electress', 'feodora', 'margravine', 'vadhana']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tBOW5:: Top 5 results: ['princess', 'hohenlohe-langenburg', 'duchess', 'bourbon-parma', 'vadhana']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['princess', 'duchess', 'margravine', 'landgravine', 'electress']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tboy:girl::man:woman\n",
      "\t\tBOW2:: Top 5 results: ['woman', 'person', 'divorcee', 'seductress', 'villager']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['woman', 'stranger', 'person', 'divorcee', 'villager']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['woman', 'seductress', 'loner', 'shepherdess', 'divorcee']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tson:daughter::boy:girl\n",
      "\t\tBOW2:: Top 5 results: ['girl', 'schoolgirl', 'tomboy', 'housemaid', 'waif']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['girl', 'schoolgirl', 'twelve-year-old', 'spunky', '13-year-old']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['girl', 'schoolgirl', 'woman', 'waitress', 'toddler']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tgrandpa:grandma::policeman:policewoman\n",
      "\t\tBOW2:: Top 5 results: ['policewoman', 'policemen', 'shoplifter', 'shopkeeper', 'firefighter']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['policewoman', 'prostitute', 'housewife', 'schoolteacher', 'housemaid']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['policewoman', 'patrolman', 'policemen', 'shopkeeper', 'firefighter']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram1-adjective-to-adverb\n",
      "\trapid:rapidly::serious:seriously\n",
      "\t\tBOW2:: Top 5 results: ['quickly', 'slowly', 'gradually', 'steadily', 'seriously']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.2\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['quickly', 'slowly', 'gradually', 'steadily', 'seriously']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.2\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['quickly', 'gracefully', 'swiftly', 'steadily', 'powerfully']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.002145922746781116\n",
      "\n",
      "\n",
      "\n",
      "\tcheerful:cheerfully::serious:seriously\n",
      "\t\tBOW2:: Top 5 results: ['inadvertantly', 'severe', 'niggling', 'meekly', 'tactfully']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.0010330578512396695\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['severe', 'keithbob', 'futher', 'remedying', 'proofreader77']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.008064516129032258\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['gleefully', 'shamelessly', 'adaptively', 'affirmatively', 'preemptively']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.0008525149190110827\n",
      "\n",
      "\n",
      "\n",
      "\tamazing:amazingly::slow:slowly\n",
      "\t\tBOW2:: Top 5 results: ['frustratingly', 'excruciatingly', 'sluggish', 'terrifically', 'phenomenally']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.0028328611898017\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['sluggish', 'fast', 'remarkably', 'terribly', 'painfully']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.013157894736842105\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['psychically', 'rhythmically', 'unpredictably', 'predictably', 'purposefully']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.0007189072609633358\n",
      "\n",
      "\n",
      "\n",
      "\tsafe:safely::furious:furiously\n",
      "\t\tBOW2:: Top 5 results: ['enraged', 'disgusted', 'infuriated', 'angrily', 'incensed']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.1\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['enraged', 'infuriated', 'distraught', 'promptly', 'angrily']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.05263157894736842\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['forcibly', 'forcefully', 'swiftly', 'violently', 'angrily']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.07692307692307693\n",
      "\n",
      "\n",
      "\n",
      "\thappy:happily::lucky:luckily\n",
      "\t\tBOW2:: Top 5 results: ['callously', 'innocently', 'greedily', 'gambles', 'bludgeons']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.003875968992248062\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['prancer', 'pingg', 'accidentally', 'sweety', 'unknowingly']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.037037037037037035\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['unhappily', 'impulsively', 'discreetly', 'helplessly', 'joyfully']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.07142857142857142\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram2-opposite\n",
      "\tproductive:unproductive::competitive:uncompetitive\n",
      "\t\tBOW2:: Top 5 results: ['uncompetitive', 'unsanctioned', 'underwhelming', 'unfair', 'uncoordinated']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['uncompetitive', 'non-competitive', 'unfair', 'unconvincing', 'unregulated']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['uncompetitive', 'non-competitive', 'uncontrollable', 'avoidable', 'unsanitary']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tcomfortable:uncomfortable::convincing:unconvincing\n",
      "\t\tBOW2:: Top 5 results: ['baffling', 'unconvincing', 'incredulous', 'unsettling', 'infuriating']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['unconvincing', 'far-fetched', 'troubling', 'compelling', 'baffling']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['compelling', 'reassuring', 'infuriating', 'shocking', 'upsetting']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.14285714285714285\n",
      "\n",
      "\n",
      "\n",
      "\tacceptable:unacceptable::responsible:irresponsible\n",
      "\t\tBOW2:: Top 5 results: ['accountable', 'blamed', 'uncalled', 'liable', 'castigated']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.01282051282051282\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['blamed', 'responsibility', 'uncalled', 'reprimanded', 'overseeing']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.03225806451612903\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['liable', 'accountable', 'culpable', 'unprepared', 'unrepentant']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.16666666666666666\n",
      "\n",
      "\n",
      "\n",
      "\tsure:unsure::certain:uncertain\n",
      "\t\tBOW2:: Top 5 results: ['non-heterosexual', 'uncertain', 'non-criminal', 'unclear', 'non-sexual']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['specific', 'differing', 'particular', 'varying', 'pre-determined']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.05555555555555555\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['sceptical', 'uncertain', 'certian', 'apprehensive', 'disdainful']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.5\n",
      "\n",
      "\n",
      "\n",
      "\tefficient:inefficient::fortunate:unfortunate\n",
      "\t\tBOW2:: Top 5 results: ['unlucky', 'unfortunate', 'anxious', 'disheartening', 'bothersome']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['unlucky', 'understandably', 'overworked', 'frustrating', 'indebted']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.14285714285714285\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['frail', 'unlucky', 'impotent', 'imprudent', 'unfortunate']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram3-comparative\n",
      "\tyoung:younger::high:higher\n",
      "\t\tBOW2:: Top 5 results: ['higher', 'lower', 'low', 'hs', 'elementary']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['elementary', 'junior-senior', 'higher', 'punahou', 'k-5']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.3333333333333333\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['higher', 'lower', 'near-zero', 'steadier', 'low']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tdeep:deeper::new:newer\n",
      "\t\tBOW2:: Top 5 results: ['newer', 'australia-new', 'then-new', 'york-new', 'brand-new']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['newer', 'ny', 'simpler', 'stronger', 'world-telegram']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['d-new', 'australia-new', 'newish', 'sillier', 'newer']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.2\n",
      "\n",
      "\n",
      "\n",
      "\tbig:bigger::loud:louder\n",
      "\t\tBOW2:: Top 5 results: ['louder', 'nastier', 'higher-pitched', 'muffled', 'shrill']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['louder', 'shrill', 'quieter', 'noisier', 'muffled']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['louder', 'funnier', 'stronger', 'tougher', 'heavier']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tlarge:larger::bright:brighter\n",
      "\t\tBOW2:: Top 5 results: ['brighter', 'redder', 'bluer', 'fainter', 'duller']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['brighter', 'bluer', 'darker', 'redder', 'fainter']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['brighter', 'whiter', 'richer', 'redder', 'bluer']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\thigh:higher::great:greater\n",
      "\t\tBOW2:: Top 5 results: ['tremendous', 'greater', 'lesser', 'considerable', 'bigger']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['considerable', 'tremendous', 'bigger', 'greater', 'larger']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.25\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['greater', 'florenz', 'sillier', 'uttermost', 'tremendous']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram4-superlative\n",
      "\teasy:easiest::cold:coldest\n",
      "\t\tBOW2:: Top 5 results: ['mildest', 'coldest', 'colder', 'driest', 'frigid']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['mildest', 'colder', 'wet', 'freezing', 'tropics']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.1\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['mildest', 'lightest', 'warmest', 'healthiest', 'driest']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.14285714285714285\n",
      "\n",
      "\n",
      "\n",
      "\tbig:biggest::short:shortest\n",
      "\t\tBOW2:: Top 5 results: ['longest', 'shortest', 'brief', 'largest', 'highest-grossing']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tBOW5:: Top 5 results: ['best-known', 'longest', 'greatest', 'shortest', 'finest']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.25\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['shortest', 'longest', 'second-longest', 'busiest', 'slowest']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tquick:quickest::short:shortest\n",
      "\t\tBOW2:: Top 5 results: ['shortest', 'longest', 'second-fastest', 'second-longest', 'smoothest']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['shortest', 'longest', 'fastest', 'shorter', 'third-longest']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['shortest', 'slowest', 'second-longest', 'thinnest', 'quietest']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tlucky:luckiest::small:smallest\n",
      "\t\tBOW2:: Top 5 results: ['smallish', 'middle-sized', 'tiny', 'largish', 'moderate-sized']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.005235602094240838\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['large', 'tiny', 'middle-sized', 'smallest', 'smaller']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.25\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['smallish', 'moderate-sized', 'good-sized', 'middle-sized', 'largish']\n",
      "\t\tDEPS:: Reciprocal Rank: 8.850340738118418e-05\n",
      "\n",
      "\n",
      "\n",
      "\tlong:longest::good:best\n",
      "\t\tBOW2:: Top 5 results: ['excellent', 'finest', 'oldest', 'second-best', 'decent']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.16666666666666666\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['perfect', 'oldest', 'highest', 'excellent', 'longest-serving']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.058823529411764705\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['nicest', 'third-most', 'wisest', 'second-best', 'noblest']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.00040617384240454913\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram5-present-participle\n",
      "\tfly:flying::invent:inventing\n",
      "\t\tBOW2:: Top 5 results: ['inventing', 'invents', 'devise', 'devising', 'invented']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['inventing', 'invented', 'devising', 'devised', 'invents']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['inventing', 'deconstructing', 'mass-producing', 'co-authoring', 'concocting']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tdance:dancing::say:saying\n",
      "\t\tBOW2:: Top 5 results: ['saying', 'says', 'opine', 'muttered', 'aver']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['saying', 'presume', 'think', 'believe', 'implying']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['quipping', 'intimating', 'muttering', 'hypothesizing', 'exclaiming']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.03333333333333333\n",
      "\n",
      "\n",
      "\n",
      "\tplay:playing::describe:describing\n",
      "\t\tBOW2:: Top 5 results: ['describing', 'describes', 'characterize', 'define', 'referring']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['describing', 'refer', 'characterize', 'characterizing', 'referring']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['describing', 'characterizing', 'characterising', 'deriding', 'picturing']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tlook:looking::describe:describing\n",
      "\t\tBOW2:: Top 5 results: ['referring', 'describing', 'refer', 'define', 'referred']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['referring', 'describing', 'refer', 'refering', 'characterize']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['describing', 'characterising', 'characterizing', 'characterize', 'connoting']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tlisten:listening::shuffle:shuffling\n",
      "\t\tBOW2:: Top 5 results: ['shuffling', 'shuffles', 'strumming', 'swapping', 'shuffled']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['shuffling', 'shuffles', 'rock-and-roll', 'strumming', 'post-disco']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['shuffling', 'juggling', 'twirling', 'strumming', 'crunching']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram6-nationality-adjective\n",
      "\tportugal:portuguese::france:french\n",
      "\t\tBOW2:: Top 5 results: ['french', 'spanish', 'dutch', 'belgian', 'piedmontese']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['french', 'spanish', 'luxembourgish', 'alsatian', 'crole']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['dutch', 'french', 'spanish', 'genoese', 'piedmontese']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.5\n",
      "\n",
      "\n",
      "\n",
      "\tbrazil:brazilian::thailand:thai\n",
      "\t\tBOW2:: Top 5 results: ['thai', 'malaysian', 'cambodian', 'singaporean', 'indonesian']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['thai', 'malaysian', 'cambodian', 'indonesian', 'laotian']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['panamanian', 'peruvian', 'colombian', 'nigerian', 'malaysian']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.00015552099533437013\n",
      "\n",
      "\n",
      "\n",
      "\targentina:argentinean::england:english\n",
      "\t\tBOW2:: Top 5 results: ['england-based', 'edinburgh-based', 'english-canadian', 'antiguan', 'english-american']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.016129032258064516\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['bromsgrove', 'yorkshire', 'heckmondwike', 'stockton-on-tees', 'lancashire']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.002325581395348837\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['zealand-born', 'polish-born', 'african-born', 'scottish-born', 'majorcan']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.00010339123242349049\n",
      "\n",
      "\n",
      "\n",
      "\tswitzerland:swiss::russia:russian\n",
      "\t\tBOW2:: Top 5 results: ['russian', 'ukrainian', 'bulgarian', 'belarusian', 'romanian']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['russian', 'ukrainian', 'belarusian', 'kazakh', 'latvian']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['austrian', 'czechoslovakian', 'argentinian', 'mauritanian', 'abkhazian']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.041666666666666664\n",
      "\n",
      "\n",
      "\n",
      "\tengland:english::poland:polish\n",
      "\t\tBOW2:: Top 5 results: ['kashubian', 'polish', 'tagalog', 'serbo-croatian', 'portugese']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['polish', 'silesian', 'kashubian', 'ukranian', 'serbo-croatian']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['portugese', 'spanish', 'finnish', 'polish', 'french']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram7-past-tense\n",
      "\tstriking:struck::looking:looked\n",
      "\t\tBOW2:: Top 5 results: ['looked', 'bumped', 'railroaded', 'funneled', 'glanced']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['looked', 'searching', 'asking', 'stricken', 'searched']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['looked', 'glanced', 'gazed', 'look', 'searched']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tfeeding:fed::writing:wrote\n",
      "\t\tBOW2:: Top 5 results: ['write', 'poetry', 'written', 'writen', 'summed']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.034482758620689655\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['write', 'written', 'co-editing', 'enthused', 'writting']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.16666666666666666\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['writen', 'blogged', 'prefaced', 'penned', 'written']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.05263157894736842\n",
      "\n",
      "\n",
      "\n",
      "\tdecreasing:decreased::knowing:knew\n",
      "\t\tBOW2:: Top 5 results: ['realizing', 'knows', 'learns', 'realising', 'knew']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.2\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['realizing', 'realising', 'knew', 'learns', 'knows']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.3333333333333333\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['realising', 'realizing', 'forewarned', 'know', 'intimated']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.009615384615384616\n",
      "\n",
      "\n",
      "\n",
      "\twalking:walked::taking:took\n",
      "\t\tBOW2:: Top 5 results: ['took', 'taken', 'take', 'takes', 'leaped']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['took', 'take', 'taken', 'takes', 'jumped']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['took', 'take', 'taken', 'reassumed', 'snared']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tknowing:knew::spending:spent\n",
      "\t\tBOW2:: Top 5 results: ['spent', 'spend', 'spends', 'expenditure', 'expenditures']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['spent', 'spend', 'spends', 'wasted', 'enjoyed']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['spent', 'spend', 'spends', 'toiled', 'vacationed']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram8-plural\n",
      "\twoman:women::donkey:donkeys\n",
      "\t\tBOW2:: Top 5 results: ['lemmings', 'ponies', 'oxen', 'donkeys', 'yaks']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.25\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['konga', 'lemmings', 'carts', 'free-roaming', 'donkeys']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.2\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['sheep', 'donkeys', 'yaks', 'heifers', 'camels']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.5\n",
      "\n",
      "\n",
      "\n",
      "\tchild:children::goat:goats\n",
      "\t\tBOW2:: Top 5 results: ['goats', 'sheep', 'zebu', 'shorthorn', 'yaks']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['cows', 'sheep', 'goats', 'cow', 'hog']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.3333333333333333\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['yaks', 'goats', 'alpacas', 'turkeys', 'boar']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.5\n",
      "\n",
      "\n",
      "\n",
      "\tbird:birds::eye:eyes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tBOW2:: Top 5 results: ['ear', 'eyes', 'warts', 'eyelid', 'non-humans']\n",
      "\t\tBOW2:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['eyelids', 'eyes', 'eyelid', 'lesions', 'ocular']\n",
      "\t\tBOW5:: Reciprocal Rank: 0.5\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['eyes', 'lungs', 'ear', 'testes', 'testicles']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\teagle:eagles::bottle:bottles\n",
      "\t\tBOW2:: Top 5 results: ['bottles', 'steelers', 'corks', 'panthers', 'redskins']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['bottles', 'corks', 'drink', 'fridge', 'cans']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['bottles', 'cans', 'jug', 'pot', 'buckets']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tdonkey:donkeys::cow:cows\n",
      "\t\tBOW2:: Top 5 results: ['cows', 'chickens', 'mules', 'yaks', 'alpacas']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['cows', 'sheep', 'goats', 'cattle', 'calves']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['cows', 'yaks', 'silkworms', 'alpacas', 'ostriches']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task: gram9-plural-verbs\n",
      "\tspeak:speaks::increase:increases\n",
      "\t\tBOW2:: Top 5 results: ['increases', 'decrease', 'increased', 'decreases', 'reduces']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['increases', 'decrease', 'increasing', 'increased', 'reduces']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['decrease', 'increases', 'decreases', 'boosts', 'lessens']\n",
      "\t\tDEPS:: Reciprocal Rank: 0.5\n",
      "\n",
      "\n",
      "\n",
      "\tenhance:enhances::describe:describes\n",
      "\t\tBOW2:: Top 5 results: ['describes', 'characterizes', 'describing', 'discusses', 'characterises']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['describes', 'describing', 'characterizes', 'discusses', 'characterize']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['describes', 'characterizes', 'characterises', 'encapsulates', 'conflates']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tdecrease:decreases::vanish:vanishes\n",
      "\t\tBOW2:: Top 5 results: ['vanishes', 'disappears', 'shrinks', 'disappear', 'crumbles']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['vanishes', 'disappears', 'disappear', 'shrinks', 'r-modules']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['vanishes', 'disappear', 'disintegrates', 'crumbles', 'disappears']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tvanish:vanishes::eat:eats\n",
      "\t\tBOW2:: Top 5 results: ['eats', 'ate', 'chews', 'ingests', 'vomits']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['eats', 'ate', 'consumes', 'vomits', 'eaten']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['eats', 'ate', 'bakes', 'sleeps', 'vomits']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\tincrease:increases::decrease:decreases\n",
      "\t\tBOW2:: Top 5 results: ['decreases', 'reduces', 'decreasing', 'diminishes', 'decreased']\n",
      "\t\tBOW2:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tBOW5:: Top 5 results: ['decreases', 'decreasing', 'reduces', 'lowers', 'diminishes']\n",
      "\t\tBOW5:: Reciprocal Rank: 1.0\n",
      "\n",
      "\t\tDEPS:: Top 5 results: ['decreases', 'reduces', 'diminishes', 'fluctuates', 'lowers']\n",
      "\t\tDEPS:: Reciprocal Rank: 1.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def execute_samples(task, data, task_labels, models, n=5):\n",
    "    random.seed(42)\n",
    "    data = [sample for (sample, task_label) in zip(data, task_labels) if task_label == task]\n",
    "    choices = [random.choice(data) for _ in range(n)]\n",
    "    for (a, a_star, b, b_star_actual) in choices:\n",
    "        print(\"\\t{}:{}::{}:{}\".format(a, a_star, b, b_star_actual))\n",
    "        for model_name, model in models:\n",
    "            if b_star_actual not in model.word_index:\n",
    "                continue\n",
    "                \n",
    "            b_star = compute_wv(model, a, a_star, b)\n",
    "\n",
    "            if b_star is None:\n",
    "                continue\n",
    "                \n",
    "            results = model.most_similar_to_vector(b_star, n = len(model.embeddings))\n",
    "            # exclude these\n",
    "            results = [r for r in results if r not in {a, a_star, b}]\n",
    "            print(\"\\t\\t{}:: Top 5 results: {}\".format(model_name, results[:5]))\n",
    "            print(\"\\t\\t{}:: Reciprocal Rank: {}\".format(model_name, reciprocal_rank(b_star_actual, results)))\n",
    "            print()\n",
    "        print(\"\\n\")\n",
    "    \n",
    "for task in np.unique(task_labels):\n",
    "    print(\"Task: {}\".format(task))\n",
    "    execute_samples(task, analogy_data, task_labels, models)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we go over each task and discuss the output of the previous experiment, and try to rationalize the quantitative results obtained in the previous section\n",
    "#### Task: capital-common-countries\n",
    "- BOW2 and BOW5 perform very well in this task. While DEPS does well on the last two examples, it's overall performance is lower than the BOW models. We can also argue that it performs well on the 'athens:greece::london:england' question, since the 3rd item is 'Britain'. \n",
    "- DEPS lower performance is probably due to the fact that context built using dependencies do not necessarily capture the information required to capture country-capital relations. \n",
    "\n",
    "#### Task: capital-world, city-in-state\n",
    "- Both of these tasks have similar relative performance w.r.t the models, like the previous task. In general, we can expect slightly worse performance, due to the relative sparsity of the data under consideration - the first task has only 'common' countries. \n",
    "- DEPS again performs badly for the same reasons described in the previous task.\n",
    "- Interesting sample: 'miami:florida::chandler:arizona' . All models perform poorly on this example. This maybe due to the fact that 'chandler' occurs in more contexts (ex. as a name) than the previous samples. This is reflected in the top 5 results for all 3 models, since most of them are names of people.\n",
    "\n",
    "#### Task: currency\n",
    "- This task has the worse performance among all other tasks. This maybe due to the nature of the corpus itself. If it is trained on data that doesn't contain as many references to other currencies e.g. if it is trained on data primarily from the Americas, it would have references to 'dollar' or 'peso', but not 'rupee' or 'yen'\n",
    "- Interesting sample: armenia:dram::argentina:peso : With this example all models return computer component names ('sdram', 'ddr2' etc)\n",
    "\n",
    "#### Task: family\n",
    "- For this task, all models perform about the same. We can see in the samples that all 3 models perfectly answer 4/5 questions\n",
    "- The question 'nephew:niece::husband:wife' performs poorly for all 3 models\n",
    "\n",
    "#### Task: gram1-adjective-to-adverb\n",
    "- All models perform very poorly on this task, with DEPS performing the worst.\n",
    "- We can expect the 3 models to perform poorly. This type of information requires lexical knowledge, which isn't available to the models directly. \n",
    "- We note that DEPS and BOW2 return words ending with 'ly' in almost all top results, but it isn't the case with the BOW5 model, which is a sensisible since BOW5 is more 'topical' than BOW2 / DEPS\n",
    "\n",
    "#### Task: gram2-opposite\n",
    "- Interesting sample: efficient:inefficient::fortunate:unfortunate\n",
    "   - All models return words somewhat related to 'unfortunate', but are unable to properly find the right word.  \n",
    "- Interesting sample: acceptable:unacceptable::responsible:irresponsible\n",
    "  - In this sample, we can see that most of the results words typically in a 'negative' setting, and somewhat sematically related to irresponsibility. \n",
    "\n",
    "#### Task: gram3-comparative\n",
    "- Excellent results for all 3 models\n",
    "- Interesting sample: 'high:higher::great:greater'\n",
    "  - Even though the models have relatively lower RR for this example, all models seem to capture the general meaning. This even brings into question the evaluation metric used - MRR\n",
    "  \n",
    "#### Task: gram4-superlative\n",
    "- All models perform the same, with all of them performing much better on the previous task. \n",
    "- Interesting sample: lucky:luckiest::small:smallest\n",
    "   - DEPS gives a very interesting result. We notice that, as expected, all the words returned by the model are related in the sense that they refer to size. However, except the first result, none of them actually capture the proper meaning. This shows that this model excels at finding related words, but falls short when it comes to computing similar words. This property applies to all other words\n",
    "\n",
    "#### Task: gram5-present-participle\t\n",
    "- Interesting sample: dance:dancing::say:saying\n",
    "  - We note that the results of the DEPS model again, are words that are related, but not really exactly the answer. \n",
    "  \n",
    "#### Task: gram6-nationality-adjective\n",
    "- This model has the largest gaps in performance between the DEPS and BOW models. \n",
    "- All results from DEPS are related words, maybe sharing the same dependency structures. \n",
    "- BOW models have no trouble predicting the correct answers for the frequent nationalities, while DEPS seems to struggle with it.\n",
    "\n",
    "#### Task: gram7-past-tense\n",
    "- DEPS outperforms BOW models in this task. This is probably due to past tense words sharing similar dependency structures\n",
    "- Interesting sample: feeding:fed::writing:wrote\n",
    "  - BOW models capture the sense, but fail to capture the tense. DEPS models also performs relatively poor here, although it returns a mispelling of the word 'written' \n",
    "  \n",
    "#### Task: gram8-plural, gram9-plural-verbs\n",
    "- All 3 models perform about the same for the gram8-plural task, while DEPS performs the best for the gram9-plural-verbs task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW2\n",
    "Accuracy: 0.5928964586146017, MRR: 0.6738476055502349 \n",
    "\n",
    "Task: capital-common-countries:: Accuracy: 0.8359683794466403, MRR: 0.8817258077741364\n",
    "\n",
    "Task: capital-world:: Accuracy: 0.6301945181255526, MRR: 0.7194812770755393\n",
    "\n",
    "Task: city-in-state:: Accuracy: 0.3923794081880827, MRR: 0.4976112176150989\n",
    "\n",
    "Task: currency:: Accuracy: 0.1130030959752322, MRR: 0.14801165297319077\n",
    "\n",
    "Task: family:: Accuracy: 0.7944664031620553, MRR: 0.8538134449938941\n",
    "\n",
    "Task: gram1-adjective-to-adverb:: Accuracy: 0.1592741935483871, MRR: 0.2357158319077029\n",
    "\n",
    "Task: gram2-opposite:: Accuracy: 0.35591133004926107, MRR: 0.42342064938705753\n",
    "\n",
    "Task: gram3-comparative:: Accuracy: 0.8956456456456456, MRR: 0.9388533621508531\n",
    "\n",
    "Task: gram4-superlative:: Accuracy: 0.6306818181818182, MRR: 0.7300379939681495\n",
    "\n",
    "Task: gram5-present-participle:: Accuracy: 0.6268939393939394, MRR: 0.7470184960322382\n",
    "\n",
    "Task: gram6-nationality-adjective:: Accuracy: 0.7417135709818636, MRR: 0.8073374035779143\n",
    "\n",
    "Task: gram7-past-tense:: Accuracy: 0.5570512820512821, MRR: 0.6625581806410229\n",
    "\n",
    "Task: gram8-plural:: Accuracy: 0.7327327327327328, MRR: 0.7926475754522675\n",
    "\n",
    "Task: gram9-plural-verbs:: Accuracy: 0.8068965517241379, MRR: 0.8647319328912093\n",
    "\n",
    "### BOW5 \n",
    "Accuracy: 0.6228061065531207, MRR: 0.7111230374484191\n",
    "\n",
    "Task: capital-common-countries:: Accuracy: 0.9407114624505929, MRR: 0.9639281008846227\n",
    "\n",
    "Task: capital-world:: Accuracy: 0.7029177718832891, MRR: 0.7988549579564563\n",
    "\n",
    "Task: city-in-state:: Accuracy: 0.5127685447912445, MRR: 0.6213078533111366\n",
    "\n",
    "Task: currency:: Accuracy: 0.12229102167182662, MRR: 0.16867354008564173\n",
    "\n",
    "Task: family:: Accuracy: 0.8181818181818182, MRR: 0.8698343729395179\n",
    "\n",
    "Task: gram1-adjective-to-adverb:: Accuracy: 0.1693548387096774, MRR: 0.27214939923316167\n",
    "\n",
    "Task: gram2-opposite:: Accuracy: 0.3633004926108374, MRR: 0.43216434825773664\n",
    "\n",
    "Task: gram3-comparative:: Accuracy: 0.8303303303303303, MRR: 0.8916557740521935\n",
    "\n",
    "Task: gram4-superlative:: Accuracy: 0.5710227272727273, MRR: 0.6987903418881215\n",
    "\n",
    "Task: gram5-present-participle:: Accuracy: 0.6704545454545454, MRR: 0.7818590311557159\n",
    "\n",
    "Task: gram6-nationality-adjective:: Accuracy: 0.8236397748592871, MRR: 0.8648149066187605\n",
    "\n",
    "Task: gram7-past-tense:: Accuracy: 0.5467948717948717, MRR: 0.6661794735807756\n",
    "\n",
    "Task: gram8-plural:: Accuracy: 0.6681681681681682, MRR: 0.7522690196093208\n",
    "\n",
    "Task: gram9-plural-verbs:: Accuracy: 0.735632183908046, MRR: 0.821760919807262\n",
    "\n",
    "### Deps\n",
    "\n",
    "Accuracy: 0.36719075385256145, MRR: 0.4457027196317186\n",
    "\n",
    "Task: capital-common-countries:: Accuracy: 0.35177865612648224, MRR: 0.49386809562252204\n",
    "\n",
    "Task: capital-world:: Accuracy: 0.11206896551724138, MRR: 0.2034998414570093\n",
    "\n",
    "Task: city-in-state:: Accuracy: 0.12282124037292258, MRR: 0.22087180510353727\n",
    "\n",
    "Task: currency:: Accuracy: 0.06375838926174497, MRR: 0.09589387260282986\n",
    "\n",
    "Task: family:: Accuracy: 0.8162055335968379, MRR: 0.8541289814671902\n",
    "\n",
    "Task: gram1-adjective-to-adverb:: Accuracy: 0.034274193548387094, MRR: 0.06706805210731484\n",
    "\n",
    "Task: gram2-opposite:: Accuracy: 0.4002463054187192, MRR: 0.47634700311122624\n",
    "\n",
    "Task: gram3-comparative:: Accuracy: 0.801051051051051, MRR: 0.8534634128403255\n",
    "\n",
    "Task: gram4-superlative:: Accuracy: 0.5606060606060606, MRR: 0.6372342387939611\n",
    "\n",
    "Task: gram5-present-participle:: Accuracy: 0.646780303030303, MRR: 0.7402042631095018\n",
    "\n",
    "Task: gram6-nationality-adjective:: Accuracy: 0.12132582864290181, MRR: 0.21989590316716345\n",
    "\n",
    "Task: gram7-past-tense:: Accuracy: 0.658974358974359, MRR: 0.7319858707885283\n",
    "\n",
    "Task: gram8-plural:: Accuracy: 0.6756756756756757, MRR: 0.7478410747404471\n",
    "\n",
    "Task: gram9-plural-verbs:: Accuracy: 0.9091954022988505, MRR: 0.9447645130880642"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
