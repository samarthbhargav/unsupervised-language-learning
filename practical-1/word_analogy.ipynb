{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_analogy_data(path):\n",
    "    with open(path) as reader:\n",
    "        analogy_data = []\n",
    "        task_labels = []\n",
    "        for line in reader:\n",
    "            if line.startswith(\":\"):\n",
    "                task = line.strip().strip(\":\").strip()\n",
    "                continue\n",
    "            # convert to lower-case \n",
    "            analogy_data.append(line.strip().lower().split())\n",
    "            task_labels.append(task)\n",
    "    return analogy_data, task_labels\n",
    "analogy_data, task_labels = read_analogy_data(\"./data/questions-words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['athens', 'greece', 'baghdad', 'iraq'],\n",
       "  ['athens', 'greece', 'bangkok', 'thailand'],\n",
       "  ['athens', 'greece', 'beijing', 'china'],\n",
       "  ['athens', 'greece', 'berlin', 'germany'],\n",
       "  ['athens', 'greece', 'bern', 'switzerland'],\n",
       "  ['athens', 'greece', 'cairo', 'egypt'],\n",
       "  ['athens', 'greece', 'canberra', 'australia'],\n",
       "  ['athens', 'greece', 'hanoi', 'vietnam'],\n",
       "  ['athens', 'greece', 'havana', 'cuba'],\n",
       "  ['athens', 'greece', 'helsinki', 'finland']],\n",
       " ['capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries',\n",
       "  'capital-common-countries'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of sub-categories\n",
    "analogy_data[:10], task_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'capital-common-countries': 506,\n",
       "         'capital-world': 4524,\n",
       "         'city-in-state': 2467,\n",
       "         'currency': 866,\n",
       "         'family': 506,\n",
       "         'gram1-adjective-to-adverb': 992,\n",
       "         'gram2-opposite': 812,\n",
       "         'gram3-comparative': 1332,\n",
       "         'gram4-superlative': 1122,\n",
       "         'gram5-present-participle': 1056,\n",
       "         'gram6-nationality-adjective': 1599,\n",
       "         'gram7-past-tense': 1560,\n",
       "         'gram8-plural': 1332,\n",
       "         'gram9-plural-verbs': 870})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(task_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow2_sim = load_model(\"bow2.words\")\n",
    "#bow5_sim = load_model(\"bow5.words\")\n",
    "#deps_sim = load_model(\"deps.words\")\n",
    "\n",
    "# models = {\n",
    "#     \"bow2\": bow2_sim,\n",
    "#     \"bow5\": bow5_sim,\n",
    "#     \"deps\": deps_sim\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank(correct_value, results):\n",
    "    try:\n",
    "        position = results.index(correct_value)\n",
    "        return 1 / (position + 1)\n",
    "    except:\n",
    "        return 0 \n",
    "\n",
    "# tests\n",
    "# print(reciprocal_rank(\"cats\", [\"catten\", \"cati\", \"cats\"]))\n",
    "# print(reciprocal_rank(\"tori\", [\"catten\", \"tori\", \"cats\"]))\n",
    "# print(reciprocal_rank(\"virus\", [\"virus\", \"cati\", \"cats\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:  capital-common-countries\n",
      "\tPreprocessing: 0 of 19544\n",
      "\tPreprocessing: 250 of 19544\n",
      "\tPreprocessing: 500 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (506, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  capital-world\n",
      "\tPreprocessing: 750 of 19544\n",
      "\tPreprocessing: 1000 of 19544\n",
      "\tPreprocessing: 1250 of 19544\n",
      "\tPreprocessing: 1500 of 19544\n",
      "\tPreprocessing: 1750 of 19544\n",
      "\tPreprocessing: 2000 of 19544\n",
      "\tPreprocessing: 2250 of 19544\n",
      "\tPreprocessing: 2500 of 19544\n",
      "\tPreprocessing: 2750 of 19544\n",
      "\tPreprocessing: 3000 of 19544\n",
      "\tPreprocessing: 3250 of 19544\n",
      "\tPreprocessing: 3500 of 19544\n",
      "\tPreprocessing: 3750 of 19544\n",
      "\tPreprocessing: 4000 of 19544\n",
      "\tPreprocessing: 4250 of 19544\n",
      "\tPreprocessing: 4500 of 19544\n",
      "\tPreprocessing: 4750 of 19544\n",
      "\tPreprocessing: 5000 of 19544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/samarth/Data/workspaces/uva/ull/unsupervised-language-learning/lib/python3.5/site-packages/ipykernel_launcher.py:79: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/media/samarth/Data/workspaces/uva/ull/unsupervised-language-learning/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/media/samarth/Data/workspaces/uva/ull/unsupervised-language-learning/lib/python3.5/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t ... done. Constructed word matrix of size: (4524, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  city-in-state\n",
      "\tPreprocessing: 6000 of 19544\n",
      "\tPreprocessing: 6250 of 19544\n",
      "\tPreprocessing: 6500 of 19544\n",
      "\tPreprocessing: 6750 of 19544\n",
      "\tPreprocessing: 7000 of 19544\n",
      "\tPreprocessing: 7250 of 19544\n",
      "\tPreprocessing: 7500 of 19544\n",
      "\tPreprocessing: 7750 of 19544\n",
      "\tPreprocessing: 8000 of 19544\n",
      "\tPreprocessing: 8250 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (2467, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  currency\n",
      "\tPreprocessing: 5250 of 19544\n",
      "\tPreprocessing: 5500 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (646, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  family\n",
      "\tPreprocessing: 8500 of 19544\n",
      "\tPreprocessing: 8750 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (506, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram1-adjective-to-adverb\n",
      "\tPreprocessing: 9000 of 19544\n",
      "\tPreprocessing: 9250 of 19544\n",
      "\tPreprocessing: 9500 of 19544\n",
      "\tPreprocessing: 9750 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (992, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram2-opposite\n",
      "\tPreprocessing: 10000 of 19544\n",
      "\tPreprocessing: 10250 of 19544\n",
      "\tPreprocessing: 10500 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (812, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram3-comparative\n",
      "\tPreprocessing: 10750 of 19544\n",
      "\tPreprocessing: 11000 of 19544\n",
      "\tPreprocessing: 11250 of 19544\n",
      "\tPreprocessing: 11500 of 19544\n",
      "\tPreprocessing: 11750 of 19544\n",
      "\tPreprocessing: 12000 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (1332, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram4-superlative\n",
      "\tPreprocessing: 12250 of 19544\n",
      "\tPreprocessing: 12500 of 19544\n",
      "\tPreprocessing: 12750 of 19544\n",
      "\tPreprocessing: 13000 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (1056, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram5-present-participle\n",
      "\tPreprocessing: 13250 of 19544\n",
      "\tPreprocessing: 13500 of 19544\n",
      "\tPreprocessing: 13750 of 19544\n",
      "\tPreprocessing: 14000 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (1056, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram6-nationality-adjective\n",
      "\tPreprocessing: 14250 of 19544\n",
      "\tPreprocessing: 14500 of 19544\n",
      "\tPreprocessing: 14750 of 19544\n",
      "\tPreprocessing: 15000 of 19544\n",
      "\tPreprocessing: 15250 of 19544\n",
      "\tPreprocessing: 15500 of 19544\n",
      "\tPreprocessing: 15750 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (1599, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram7-past-tense\n",
      "\tPreprocessing: 16000 of 19544\n",
      "\tPreprocessing: 16250 of 19544\n",
      "\tPreprocessing: 16500 of 19544\n",
      "\tPreprocessing: 16750 of 19544\n",
      "\tPreprocessing: 17000 of 19544\n",
      "\tPreprocessing: 17250 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (1560, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram8-plural\n",
      "\tPreprocessing: 17500 of 19544\n",
      "\tPreprocessing: 17750 of 19544\n",
      "\tPreprocessing: 18000 of 19544\n",
      "\tPreprocessing: 18250 of 19544\n",
      "\tPreprocessing: 18500 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (1332, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: nan, MRR: nan\n",
      "Task:  gram9-plural-verbs\n",
      "\tPreprocessing: 18750 of 19544\n",
      "\tPreprocessing: 19000 of 19544\n",
      "\tPreprocessing: 19250 of 19544\n",
      "\tPreprocessing: 19500 of 19544\n",
      "\t\t ... done. Constructed word matrix of size: (870, 300)\n",
      "\tNow computing similarities!\n",
      "\tSimilarity : 0 of 183870\n",
      "\tTask: gram9-plural-verbs :: Accuracy: 0.0, MRR: 0.0\n",
      "Overall: Accuracy: 0.0, MRR: 0.0\n",
      "\t ... done\n",
      "\t Skipped: 286\n"
     ]
    }
   ],
   "source": [
    "def compute_wv(model, a, a_star, b):\n",
    "    if a not in model.word_index or a_star not in model.word_index or b not in model.word_index:\n",
    "        return None\n",
    "    a, a_star, b = model[a], model[a_star], model[b]\n",
    "    v = a_star - a\n",
    "    b_star = b + v\n",
    "    return b_star\n",
    "\n",
    "def compute_scores(data, model, task_labels):\n",
    "    skipped = 0\n",
    "    \n",
    "    overall_correct = []\n",
    "    overall_reciprocal_ranks = []\n",
    "    \n",
    "    for task_label in np.unique(task_labels):\n",
    "        print(\"Task: \", task_label)\n",
    "        word_vectors = []\n",
    "        parsed_data = []\n",
    "        \n",
    "        for index, (tlab, (a, a_star, b, b_star_actual)) in enumerate(zip(task_labels, data)):\n",
    "            if tlab != task_label:\n",
    "                continue\n",
    "            \n",
    "            # if the final word doesn't exist, then there's no point\n",
    "            if b_star_actual not in model.word_index:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            if index % 250 == 0:\n",
    "                print(\"\\tPreprocessing: {} of {}\".format(index, len(data)))\n",
    "\n",
    "            b_star = compute_wv(model, a, a_star, b)\n",
    "            if b_star is None:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            parsed_data.append((a, a_star, b, b_star_actual))\n",
    "            word_vectors.append(b_star)\n",
    "\n",
    "        word_vectors = np.array(word_vectors)\n",
    "        print(\"\\t\\t ... done. Constructed word matrix of size: {}\".format(word_vectors.shape))\n",
    "        print(\"\\tNow computing similarities!\")\n",
    "    \n",
    "        similarity_dict = defaultdict(list)\n",
    "        for index, (word, word_index) in enumerate(model.word_index.items()):\n",
    "            if index % 100 == 0:\n",
    "                print(\"\\tSimilarity : {} of {}\".format(index, len(model.word_index)))\n",
    "            word_vector = model.embeddings[word_index]\n",
    "\n",
    "            similarities = np.apply_along_axis(lambda _: cosine_similarity(word_vector, _), 1, word_vectors)\n",
    "\n",
    "            for idx, tup in enumerate(parsed_data):\n",
    "                similarity_dict[tuple(tup)].append((word, similarities[idx]))\n",
    "\n",
    "        correct = defaultdict(list)\n",
    "        reciprocal_ranks = defaultdict(list)\n",
    "\n",
    "        for tup, task in zip(data, task_labels):\n",
    "            if task != task_label:\n",
    "                continue\n",
    "            tup = tuple(tup)\n",
    "            if tup not in similarity_dict:\n",
    "                continue\n",
    "            similarity_list = similarity_dict[tup]\n",
    "            similarity_list.sort(key=lambda _: -_[1])\n",
    "            if similarity_list[0] == b_star_actual:\n",
    "                correct[task].append(1)\n",
    "            else:\n",
    "                correct[task].append(0)\n",
    "            b_star_results = [_[0] for _ in similarity_list]\n",
    "            reciprocal_ranks[task].append(reciprocal_rank(b_star_actual, b_star_results))\n",
    "\n",
    "        overall_correct.extend(correct[task])\n",
    "        overall_reciprocal_ranks.extend(reciprocal_ranks[task])\n",
    "        \n",
    "        accuracy = np.sum(correct[task]) / len(correct[task])\n",
    "        mrr = np.mean(reciprocal_ranks[task])\n",
    "        print(\"\\tTask: {} :: Accuracy: {}, MRR: {}\".format(task, accuracy, mrr))        \n",
    "        \n",
    "    overall_acc = np.sum(overall_correct) / len(overall_correct) \n",
    "    print(\"Overall: Accuracy: {}, MRR: {}\".format(overall_acc, np.mean(overall_reciprocal_ranks)))\n",
    "    \n",
    "    print(\"\\t ... done\")\n",
    "    print(\"\\t Skipped: {}\".format(skipped))\n",
    "\n",
    "compute_scores(analogy_data, bow2_sim, task_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
